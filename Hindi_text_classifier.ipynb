{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "import tensorflow as tf\n",
    "from itertools import cycle\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_set = valid_datagen.flow_from_directory('validation',\n",
    "                                                 target_size=(256, 256),\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2450 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "training_set = train_datagen.flow_from_directory('training',\n",
    "                                                 target_size=(256, 256),\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu',  padding='same'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu',  padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',  padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation=tf.nn.sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 256, 256, 16)      448       \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 256, 256, 32)      4640      \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 256, 256, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 128, 128, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 78,593\n",
      "Trainable params: 78,401\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "15/15 [==============================] - 53s 4s/step - loss: 0.4745 - accuracy: 0.7811\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 56s 4s/step - loss: 0.4438 - accuracy: 0.8146\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 56s 4s/step - loss: 0.4165 - accuracy: 0.8396\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 54s 4s/step - loss: 0.3786 - accuracy: 0.8455\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 56s 4s/step - loss: 0.3554 - accuracy: 0.8498\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 54s 4s/step - loss: 0.3367 - accuracy: 0.8519\n",
      "Epoch 7/15\n",
      "15/15 [==============================] - 56s 4s/step - loss: 0.3433 - accuracy: 0.8458\n",
      "Epoch 8/15\n",
      "15/15 [==============================] - 56s 4s/step - loss: 0.3724 - accuracy: 0.8229\n",
      "Epoch 9/15\n",
      "15/15 [==============================] - 56s 4s/step - loss: 0.3258 - accuracy: 0.8687\n",
      "Epoch 10/15\n",
      "15/15 [==============================] - 56s 4s/step - loss: 0.2976 - accuracy: 0.8646\n",
      "Epoch 11/15\n",
      "15/15 [==============================] - 54s 4s/step - loss: 0.3276 - accuracy: 0.8433\n",
      "Epoch 12/15\n",
      "15/15 [==============================] - 56s 4s/step - loss: 0.3468 - accuracy: 0.8479\n",
      "Epoch 13/15\n",
      "15/15 [==============================] - 55s 4s/step - loss: 0.3243 - accuracy: 0.8498\n",
      "Epoch 14/15\n",
      "15/15 [==============================] - 54s 4s/step - loss: 0.3726 - accuracy: 0.8155\n",
      "Epoch 15/15\n",
      "15/15 [==============================] - 56s 4s/step - loss: 0.2817 - accuracy: 0.8792\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "history = model.fit(training_set,\n",
    "      steps_per_epoch=15,  \n",
    "      epochs=15,\n",
    "      verbose=1,\n",
    "      validation_data = valid_set,\n",
    "      validation_steps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "# from utils.io import write_json\n",
    "\n",
    "def write_json(filename, result):\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(result, outfile)\n",
    "\n",
    "def read_json(filename):\n",
    "    with open(filename, 'r') as outfile:\n",
    "        data =  json.load(outfile)\n",
    "    return data\n",
    "\n",
    "def generate_sample_file(filename):\n",
    "    res = {}\n",
    "    for i in range(1,99):\n",
    "        test_set = str(i) + '.jpg'\n",
    "        test_image = image.load_img(test_set, target_size=(256, 256))\n",
    "        test_image = image.img_to_array(test_image)\n",
    "        test_image = np.expand_dims(test_image, axis=0)\n",
    "        result= model.predict(test_image)\n",
    "        if int(result[0][0])==1:\n",
    "            res[test_set]=0\n",
    "        else:\n",
    "            res[test_set]=1\n",
    "\n",
    "    write_json(filename, res)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    generate_sample_file('./sample_result1.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
